package com.example.qaassistant.service.rag;

import com.example.qaassistant.model.rag.KnowledgeDocument;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import java.util.*;
import java.util.stream.Collectors;

@Component
public class VectorDBCleaner {
    private static final Logger log = LoggerFactory.getLogger(VectorDBCleaner.class);

    private final RagService ragService;

    private final SimpleVectorStore simpleVectorStore;

    public VectorDBCleaner(RagService ragService, SimpleVectorStore simpleVectorStore) {
        this.ragService = ragService;
        this.simpleVectorStore = simpleVectorStore;
    }

    public void deduplicateVectorDB() {
        try {
            log.info("... Iniciando limpieza de base de datos vectorial...");

            // Estrategia: usar tu servicio existente para buscar documentos comunes
            List<String> testQueries = Arrays.asList(
                    "modelo de datos",
                    "entidades del sistema",
                    "pruebas QA",
                    "itinerarios calidad",
                    "aplicaciones",
                    "ranking cobertura"
            );

            Set<KnowledgeDocument> allDocs = new HashSet<>();

            for (String query : testQueries) {
                try {
                    // Asumiendo que tu servicio puede devolver los documentos encontrados
                    // Necesitar√°s adaptar esto seg√∫n tu implementaci√≥n
                    List<KnowledgeDocument> docs = searchDocuments(query);
                    allDocs.addAll(docs);
                    log.info("üîç Query '" + query + "' encontr√≥: " + docs.size() + " documentos");
                } catch (Exception e) {
                    log.error("‚ö†Ô∏è Error en query '" + query, e);
                }
            }

            log.info("üìä Total documentos recuperados: " + allDocs.size());

            // Identificar duplicados por contenido
            Map<String, List<KnowledgeDocument>> contentGroups = allDocs.stream()
                    .collect(Collectors.groupingBy(doc -> normalizeContent(doc.getContent())));

            // Encontrar duplicados
            Map<String, List<KnowledgeDocument>> duplicates = contentGroups.entrySet().stream()
                    .filter(entry -> entry.getValue().size() > 1)
                    .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));

            log.info("üîç Grupos de duplicados encontrados: " + duplicates.size());

            // Mantener solo documentos √∫nicos
            List<KnowledgeDocument> uniqueDocs = contentGroups.values().stream()
                    .map(group -> group.get(0)) // Primer documento de cada grupo
                    .collect(Collectors.toList());

            log.info("‚úÖ Documentos √∫nicos: " + uniqueDocs.size());

            if (!duplicates.isEmpty()) {
                // Aqu√≠ necesitar√≠as implementar la l√≥gica para reindexar
                // Depende de c√≥mo manejes tu vector store
                reindexVectorStore(uniqueDocs);

                log.info("üéâ Base de datos limpiada: " +
                        allDocs.size() + " -> " + uniqueDocs.size() + " documentos");
            } else {
                log.info("‚úÖ No se encontraron duplicados");
            }

            // Mostrar reporte de duplicados
            printDuplicateReport(duplicates);

        } catch (Exception e) {
            log.error("‚ùå Error durante la limpieza: ", e);
        }
    }


    private String normalizeContent(String content) {
        if (content == null) return "null";
        // Normalizar contenido para comparaci√≥n
        return content.replaceAll("\\s+", " ")
                .trim()
                .toLowerCase();
    }

    // M√©todo que necesitas adaptar seg√∫n tu implementaci√≥n
    private List<KnowledgeDocument> searchDocuments(String query) {

        log.info("üîç Buscando: " + query);

        // Ejemplo: si tu servicio tiene un m√©todo para buscar
        return ragService.processQuestion(query).sources();
    }

    // M√©todo para reindexar - adaptar seg√∫n tu implementaci√≥n
    private void reindexVectorStore(List<KnowledgeDocument> uniqueDocs) {
        // TODO: Implementar la l√≥gica de reindexaci√≥n seg√∫n tu vector store
        log.info("üîÑ Reindexando con " + uniqueDocs.size() + " documentos √∫nicos...");

        // 1. Limpiar vector store existente
        simpleVectorStore.deleteAll();

        // 2. A√±adir documentos √∫nicos
        simpleVectorStore.addDocs(uniqueDocs);
    }

    private void printDuplicateReport(Map<String, List<KnowledgeDocument>> duplicates) {
        if (duplicates.isEmpty()) {
            log.info("‚úÖ No se encontraron duplicados");
            return;
        }

        log.info("\nüìã INFORME DE DUPLICADOS");
        log.info("========================");

        duplicates.forEach((content, docs) -> {
            log.info("\nüîç DUPLICADO (" + docs.size() + " veces):");
            log.info("Contenido: " + content.substring(0, Math.min(100, content.length())) + "...");
            docs.forEach(doc -> {
                log.info("  - ID: " + doc.getId());
                if (doc.getMetadata() != null && !doc.getMetadata().isEmpty()) {
                    log.info("    Metadata: " + doc.getMetadata());
                }
            });
        });
    }

}